---
title: "XGBoost"
author: "Benjamin T. Carter, PhD, CSI, Billings Clinic"
date: "Generated: `r Sys.time()`"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    fig_width: 6
    fig_height: 12
    df_print: paged
params:
  respVar: "return_in_14"
  d.frame: "did you forget me?"
---

```{r data}
# ENVIRONMENT ####

# packages
library(mltools) # library for encoding?
library(xgboost)
library(dplyr)
library(caret)

# One-hot encoding ####

dummy <- dummyVars(" ~ .", data=params$d.frame)
newdata <- data.frame(predict(dummy, newdata = params$d.frame))
df <- newdata

```

# Correlations between variables


```{r correlations}

var.list <- colnames(df)

res.df <- data.frame()

for (var in var.list){
  Test <- cor.test(x = df[[params$respVar]], y = df[[var]])

  res <- data.frame("variable" = var,
                    "R2" = Test$estimate,
                    "p.val" = Test$p.value)
  res.df <- rbind(res.df, res)
}


top_50 <- res.df %>% slice_min(p.val, n = 50)
top_50 <- top_50$variable

print(paste("Features highly correlated with ", params$respVar, sep=""))

top_50

df <- df %>%
  select(
    all_of(top_50)
  )


```

# Gradient Boosting

```{r makeData}
# David's code ####

# Balance the Dataset

# Create Training Data

input_ones <- df[which(df[[params$respVar]] == 1), ] # all 1's
input_zeros <- df[which(df[[params$respVar]] == 0), ] # all 0's
nrow(input_ones)
nrow(input_zeros)

set.seed(100) # for repeatability of samples

input_ones_training_rows <- sample(1:nrow(input_ones), 0.7*nrow(input_ones)) # 1's for training
input_zeros_training_rows <- sample(1:nrow(input_zeros), 0.7*nrow(input_ones)) # 0's for training. Pick as many 0's as 1's
training_ones <- input_ones[input_ones_training_rows, ]
training_zeros <- input_zeros[input_zeros_training_rows, ]
X_train <- rbind(training_ones, training_zeros) # row bind the 1's and 0's

# Create Test Data
test_ones <- input_ones[-input_ones_training_rows, ]
test_zeros <- input_zeros[-input_zeros_training_rows, ]
X_test <- rbind(test_ones, test_zeros) # row bind the 1's and 0's

# Shuffle
X_train <- X_train[sample(nrow(X_train)),]
X_test <- X_test[sample(nrow(X_test)),]

# Extract y
y_train <- X_train %>%
  select(return_in_14)

y_test <- X_test %>%
  select(return_in_14)



# Drop y from X
label_drop <- c(params$respVar)

X_train <- X_train[ , !(names(X_train) %in% label_drop)]
X_test <- X_test[ , !(names(X_test) %in% label_drop)]

nrow(X_train)

nrow(y_train)

# Prepare Matrix

X_train <- as.matrix(X_train)
X_test <- as.matrix(X_test)

y_train <- as.matrix(y_train)
y_test <- as.matrix(y_test)

```

```{r gradientBoosting}
# train model
xg.model <- xgboost(
  data = X_train,
  label = y_train,
  max.depth = 5,
  eta = 0.05,
  # nthread = 2,
  nrounds = 1000,
  early_stopping_rounds = 50,
  objective = "binary:logistic",
  eval_metric = 'auc',
  gamma = 10,
  min_child_weight = 10
)
```

# AUC

```{r auc}
# evaluate
pred_prob_train <- predict(xg.model, X_train)
pred_prob_test <- predict(xg.model, X_test)

# AUC
library(ROCR)
pred_ROCR <- prediction(pred_prob_train, y_train[,1])
auc_ROCR_train <- performance(pred_ROCR, measure = 'auc')
auc_ROCR_train <- auc_ROCR_train@y.values[[1]]

pred_ROCR <- prediction(pred_prob_test, y_test[,1])
auc_ROCR_test <- performance(pred_ROCR, measure = 'auc')
auc_ROCR_test <- auc_ROCR_test@y.values[[1]]
auc_ROCR_test
```

AUC Train: `r auc_ROCR_train`
AUC Test: `r auc_ROCR_test`
Train/Test: `r auc_ROCR_train/auc_ROCR_test`

# Accuracy

```{r accuracy}
# Accuracy
pred_ROCR <- prediction(pred_prob_train, y_train[,1])
acc_ROCR_train <- performance(pred_ROCR, measure = 'acc')
acc_ROCR_train <- max(acc_ROCR_train@y.values[[1]])

pred_ROCR <- prediction(pred_prob_test, y_test[,1])
acc_ROCR_test <- performance(pred_ROCR, measure = 'acc')
acc_ROCR_test <- max(acc_ROCR_test@y.values[[1]])

```

ACC Train: `r acc_ROCR_train`
ACC Test: `r acc_ROCR_test`
Train/Test: `r acc_ROCR_train/acc_ROCR_test`

# Factor Importance

```{r plotFactors}
# take a peak at deciding factors
mat <- xgb.importance(feature_names=colnames(X_train), model=xg.model)
# xgb.plot.importance (importance_matrix = mat[1:32])

# plotting factors by importance
library(ggplot2)
mat.plot <- as.data.frame(mat)

mat.plot$Feature <- factor(mat.plot$Feature,
                           levels = mat.plot$Feature[order(mat.plot$Gain,
                                                           decreasing = FALSE)])

mat.plot %>% 
  slice_max(10) %>% 
  ggplot(aes(Feature, Gain)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_classic()
```


# Logistic model

```{r logisticModel}

# compare to a simple logistic model
log.mod <- glm(y_train ~ X_train, df,
    family = "binomial")

pred.res <- predict(log.mod, as.data.frame(X_test))

# evaluate
pred_prob_train <- predict(log.mod, as.data.frame(X_train))
pred_prob_test <- predict(log.mod, as.data.frame(X_test))

# AUC
library(ROCR)
pred_ROCR <- prediction(pred_prob_train, y_train[,1])
auc_ROCR_train <- performance(pred_ROCR, measure = 'auc')
auc_ROCR_train <- auc_ROCR_train@y.values[[1]]

pred_ROCR <- prediction(pred_prob_test, y_test[,1])
auc_ROCR_test <- performance(pred_ROCR, measure = 'auc')
auc_ROCR_test <- auc_ROCR_test@y.values[[1]]

```

AUC Train: `r auc_ROCR_train`
AUC Test: `r auc_ROCR_test`
Train/Test: `r auc_ROCR_train/auc_ROCR_test`

```{r logisticSum}
summary(log.mod)
```

